{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/trnmah/UET-project/summarization/drive-download-20240727T015440Z-001/train_data_new.jsonl\", 'r') as f:\n",
    "\tdata = f.readlines()\n",
    "\tdata = [json.loads(d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base-vietnews-summarization\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"VietAI/vit5-base-vietnews-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Các giáo viên bộ môn giàu kinh nghiệm đã có những chia sẻ giúp học sinh đạt kết quả cao trong kỳ thi sắp tới. Cần phải giữ sức khỏe ổn định bằng cách sinh hoạt điều độ; về việc ôn thi, không nên tập trung vào học kiến thức mới nữa, mà nên ưu tiên luyện tập chiến thuật làm bài thi. Đối với môn Ngữ văn, cần nắm chắc cấu trúc đề, dạng câu hỏi theo chuyên đề, rà soát lại các kiến thức cơ bản trong chương trình Ngữ văn lớp 12. Chiến thuật làm môn Toán là: Dễ trước, khó sau, nháp cẩn thận, khoanh vùng rõ ràng, tô đáp án cẩn thận. Đối với môn tiếng Anh,  cần tối ưu hóa điểm số dựa trên mục tiêu, làm sau và dành nhiều thời gian cho hai dạng bài khó là đọc hiểu và đọc điền. Khi làm bài Khoa học xã hội, câu dễ cần làm nhanh và chắc, câu khó làm sau, tránh căng thẳng dẫn đến những sai sót không đáng có. '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1715"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(tokenizer(data[0]['single_documents'][2]['raw_text']).attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': \"Biến đổi khí hậu khiến châu Âu 'điêu đứng' vì nắng nóng \",\n",
       "  'anchor_text': 'Nhiệt độ kỷ lục mới được ghi nhận tại Vương quốc Anh, quốc gia nổi tiếng với khí hậu ôn hòa và nhiều mưa. Đây là một phần trong đợt sóng nhiệt nóng và khô bất thường đang càn quét khắp châu Âu, ảnh hưởng trực tiếp tới sức khỏe con người, cơ sở hạ tầng và môi trường - làm dấy lên nhiều lo ngại về biến đổi khí hậu. ',\n",
       "  'raw_text': 'Anh lần đầu ghi nhận nắng nóng trên 40 độ C\\nNhiệt kế đã chỉ 40,3 độ C tại hạt Lincolnshire, miền trung nước Anh vào lúc 4 giờ chiều (giờ địa phương), cao hơn gần 2 độ so với nhiệt độ kỷ lục cũ năm 2019. Tới chiều ngày 19/7, đã có 34 địa phương phá vỡ mức nhiệt kỷ lục trước đó.\\nNền nhiệt cao tác động xấu đến nhiều mặt của đời sống người dân đất nước này, từ giao thông tới y tế và giáo dục. Nhiều gia đình, doanh nghiệp nhỏ và cả các tòa nhà công cộng như bệnh viện tại Anh không có hệ thống điều hòa không khí. Sở Cứu hỏa London đã ra thông báo khẩn khi nhiều vụ cháy xảy ra khắp thủ đô, nhiều khu vực của nước Anh cũng đã bị ngắt quãng dịch vụ điện. Một vài tuyến đường sắt đã bị hủy do hỏng hóc đường ray và dây cáp.\\nBộ trưởng Bộ Giao thông Anh quốc Grant Shapps chỉ ra rằng hạ tầng đường sắt tại Anh không thể đối mặt với nắng nóng cực đoan và sẽ cần \"rất nhiều năm\" để những nâng cấp cần thiết được hoàn thành. Cơ sở vật chất ứng phó với kiểu thời tiết này tại Anh được nhận định là còn rất nhiều thiếu sót và bất cập.\\nẢnh trái: Biển cảnh báo nắng nóng gay gắt tại Anh, nguy cơ chảy nhựa đường và nổ lốp xe (Ảnh: Evening Standard). Ảnh phảiL Đường ray tại ga Battersea, London (Anh) bị cháy trong thời tiết nắng nóng (Ảnh: Network Rail)\\nNhiều thương vong vì nắng nóng khắp châu Âu\\nAnh không phải là quốc gia Tây Âu duy nhất có đợt nắng nóng bất thường. Thủ đô Amsterdam của Hà Lan được dự kiến đạt ngưỡng nhiệt 39 độ C. Các kỹ sư đã phải phun nước lên nhiều cây cầu để ngăn kết cấu kim loại giãn nở, cản trở giao thông đường sông tại đây.\\nNhiều cảnh báo về mức độ nguy hiểm của thời tiết đã được phát đi khắp châu Âu và Bắc Phi. Ít nhất 6 người đã chết đuối khi tìm cách hạ nhiệt trong các sông và hồ chứa tại Anh. Ở Tây Ban Nha và Bồ Đào Nha, gần 750 vụ thiệt mạng liên quan đến nắng nóng đã được báo cáo trong giai đoạn sóng nhiệt càn quét.\\nThiên tai, đặc biệt là cháy rừng cũng xảy ra ở nhiều nước: Pháp, Tây Ban Nha, Bồ Đào Nha, Hy Lạp và Morocco. Tại tây nam Pháp, hơn 2.000 lính cứu hỏa được huy động để đối phó với cháy rừng dữ dội lan nhanh qua các rừng thông khô cứng.\\nHàng chục nghìn người đã phải sơ tán khẩn cấp. Tại Hy Lạp, một đám cháy tại khu rừng phía đông bắc Athens đã làm cháy nhiều ngôi nhà ở vùng ngoại ô, tạo ra một màn khói dày có thể quan sát thấy từ thành phố.\\nTuy nhiên, dự báo cho rằng nhiệt độ tại châu Âu sẽ dịu bớt trong vài ngày tới, có thể sẽ kèm theo mưa.\\nNắng nóng - hệ quả trực tiếp của biến đổi khí hậu\\nTrưởng Văn phòng Khí tượng Anh quốc cho rằng mức nhiệt tưởng chừng bất khả thi này là hệ quả trực tiếp của biến đổi khí hậu, tạo ra bởi hiệu ứng nhà kính. Ông cho rằng nếu những khí gây nên hiệu ứng này vẫn tiếp tục được thải ra với khối lượng lớn \"chúng ta có thể thấy nhiệt độ thế này cứ mỗi 3 năm\".\\nCác đợt sóng nhiệt đang diễn ra nhiều hơn và cực đoan hơn do sự biến đổi khí hậu của con người gây nên. Theo Liên Hợp quốc, chúng ta đang ở trong giai đoạn nóng nhất trong 125 nghìn năm.\\nTuy chưa từng có tiền lệ, những sự kiện thời tiết cực đoan tại châu Âu và trên toàn thế giới đã được cảnh báo hàng thập kỷ bởi các nhà khí tượng học. Khi được hỏi liệu kiểu sóng nhiệt này có gây sự bất ngờ, nhà khí tượng học Micheal Mann trả lời: \"Đáng tiếc là không. Chúng ta đã thấy sự lặp lại của một dòng tia rất uốn lượn hè năm nay. Sự lặp lại này có liên quan tới các sự kiện khí tượng hiện giờ tại Mỹ và châu Âu\".\\nTrưởng Cơ quan Thời tiết của Liên Hợp quốc bày tỏ hy vọng rằng cái nóng tại châu Âu sẽ là hồi chuông cảnh tỉnh cho chỉnh phủ các quốc gia để hành động nhiều hơn. Các nhà khoa học khác nhấn mạnh sự cần thiết phải hành động ngay lập tức.\\nTrong bản báo cáo đặc biệt: \"Sự nóng lên toàn cầu ngưỡng 1,5 độ C\", Ủy ban Liên chính phủ về Biến đổi Khí hậu nhấn mạnh: \"Kiềm chế sự nóng lên toàn cầu ở ngưỡng 1,5 thay vì 2 độ C sẽ làm bớt đi khoảng 420 triệu người phải thường xuyên chịu những đợt sóng nhiệt cực đoan và giảm khoảng 65 triệu người phải tiếp xúc với những đợt sóng nhiệt nguy hiểm tới tính mạng\".\\nTuy nhiên, ở ngưỡng tăng 1,2 độ C hiện giờ, những tác động của biến đổi khí hậu đã được cảm nhận thấy rất rõ rệt, đặc biệt ở những tháng hè. Điều tệ nhất, theo Mann, là những nguy cơ lâu dài của sóng nhiệt có thể đã bị đánh giá thấp. \"Cơ chế mà biến đổi khí hậu làm thay đổi hoạt động của dòng tia không được chạy thử nghiệm trên những thiết bị mới nhất. Điều này nghĩa là những thử nghiệm có thể đã không cho chúng ta thấy toàn cảnh ảnh hưởng của biến đổi khí hậu\". \"Những thử nghiệm này có lẽ đã đánh giá thấp sức tàn phá khi nhiệt độ tăng đạt ngưỡng 1,5 hay 2 độ C\".\\nVí dụ của Anh, Tây Ban Nha và Bồ Đào Nha, với nhiệt độ trên dưới 40 độ C, là một lời nhắc nhở đanh thép về sự cấp bách của những hành động nghiêm túc từ chúng ta, nếu không muốn chịu những kỷ lục nhiệt độ mới.\\n\"Có sự khác biệt giữa rất khó và bất khả thi. Kiềm chế sự nóng lên ở ngưỡng 1,5 độ C chắc chắn là nỗ lực kinh tế - xã hội khổng lồ. Những không có nghĩa điều này bất khả thi\", Caroline Brouillette, Quản lý Chính sách Quốc gia của Mạng lưới Hành động vì Khí hậu Canada, chia sẻ.\\nTại thủ đô Berlin của Đức, Tổng Thư ký Liên Hợp quốc António Guterres phát biểu trước đại diện của 40 quốc gia: \"Các đại biểu, đây phải là thập kỷ của hành động dứt khoát về khí hậu. Đó nghĩa là sự tin tưởng, chủ nghĩa đa phương và sự hợp tác sâu rộng. Chúng ta có một lựa chọn. Hành động cùng nhau hoặc tự sát cùng nhau. Quyết định nằm trong tay chúng ta\".\\nTheo Ủy ban Liên chính phủ về Biến đổi Khí hậu của Liên Hợp quốc, loài người đang ở giai đoạn nóng nhất trong 125 nghìn năm, nguyên nhân chủ yếu là từ nồng độ CO2 cao nhất trong 2 triệu năm, gây ra bởi các hoạt động của con người.\\nLiên Hợp quốc đã đặt mục tiêu giới hạn sự tăng nhiệt của thế giới ở ngưỡng 1,5 độ C so với mức tiền công nghiệp. Để đạt mục tiêu, theo đà tăng của lượng khí CO2 thải ra môi trường, lượng khí phát thải cần giảm còn khoảng một nửa so với hiện tại vào năm 2030. Sau đó thế giới cần đạt phát thái ròng bằng \"0\" vào năm 2050.\\nNguồn: BBC, AP, CBC'},\n",
       " {'title': 'Lý do châu Âu trở thành điểm nóng sóng nhiệt ',\n",
       "  'anchor_text': 'Cái nóng thiêu đốt tại châu Âu năm nay phù hợp với xu hướng chung. Nguyên nhân nằm ở một số yếu tố, trong đó có sự biến đổi của các dòng tia trên Trái Đất, theo các nhà khoa học. ',\n",
       "  'raw_text': 'Hai tháng trước, Pháp trải qua tháng 5 nóng nhất trong lịch sử, với mức nhiệt cao kỷ lục ở một số thành phố. Tháng 6, Pháp lại gặp làn sóng nhiệt tác động đến cả Tây Ban Nha, Italy và các nước khác. Đến tháng 7, tới lượt Ba Lan và các vùng ở Đông Âu hứng chịu nắng nóng cực đoan.\\nNhiệt độ khắp châu Âu lúc này tiếp tục tăng mạnh, trong khi mùa hè vẫn còn hai tháng nữa mới kết thúc.\\nCác nhà khoa học cho biết hiện tượng nhiệt độ cực đoan dai dẳng phù hợp với xu hướng toàn cầu. Dù vậy, họ cho rằng sóng nhiệt ở châu Âu đang ngày một gia tăng về tần suất và cường độ, với tốc độ nhanh hơn hầu hết khu vực khác trên Trái Đất, bao gồm miền Tây nước Mỹ.\\nNguyên nhân một phần của hiện tượng trên là sự nóng lên toàn cầu, do nhiệt độ trung bình lúc này đã cao hơn 1,1 độ C so với cuối thế kỷ 19, thời điểm trước khi phát thải CO2 và các loại khí nhà kính khác trở nên phổ biến. Do đó, cái nóng cực đoan có xuất phát điểm cao hơn.\\nNhưng bên cạnh đó, một số yếu tố khác, trong đó bao gồm yếu tố liên quan tới hoàn lưu khí quyển và luân chuyển hải lưu, cũng có thể khiến châu Âu trở thành điểm nóng sóng nhiệt.\\nSự thay đổi trong dòng tia\\nKhông có hai làn sóng nhiệt nào giống nhau hoàn toàn. Đợt nhiệt lớn đang phủ lên Anh và xứ Wales vào hôm 18/7 một phần là kết quả của việc một vùng không khí áp suất thấp ở tầng trên khí quyển bị nghẽn lại ngoài khơi Bồ Đào Nha trong nhiều ngày.\\nVùng không khí áp suất thấp nói trên được gọi là “vùng áp thấp tách biệt” (cutoff low) vì nó bị tách biệt ra khỏi các luồng gió tây thường đi vòng quanh Trái Đất ở độ cao lớn, còn gọi là dòng tia. Dòng tia nói chung là các luồng không khí thổi nhanh trong các dòng hẹp ở khí quyển.\\nCác khu vực áp suất thấp thường hút không khí về phía mình. Và trong trường hợp này, vùng áp suất thấp ngoài khơi Bồ Đào Nha đã đều đặn hút không khí từ Bắc Phi về phía mình rồi đẩy vào châu Âu.\\n“(Vùng áp suất thấp ấy) đang đẩy không khí nóng về phía bắc”, Kai Kornhuber, nhà nghiên cứu thuộc Đài quan sát Trái Đất Lamont (Mỹ), nói.\\nTiến sĩ Kornhuber nằm trong số những người tham gia một nghiên cứu về khí hậu được công bố trong tháng 7. Kết quả nghiên cứu này cho thấy sóng nhiệt ở châu Âu đã gia tăng cả về tần suất và cường độ trong 40 năm qua.\\nTheo nghiên cứu, xu hướng gia tăng trên một phần do sự biến đổi trong các dòng tia gây ra. Các nhà nghiên cứu thấy rằng nhiều làn sóng nhiệt ở châu Âu xuất hiện khi dòng tia tạm thời phân đôi, tạo ra khu vực không khí áp suất cao và gió yếu lọt giữa hai nhánh. Điều này dễ khiến nhiệt độ cực đoan tích tụ.\\nEfi Rousi, một nhà khoa học cấp cao ở Viện Nghiên cứu Khí hậu Potsdam (Đức) và là tác giả chính của nghiên cứu trên, nói sóng nhiệt hiện tại có vẻ cũng có liên hệ tới hiện tượng “dòng tia phân đôi”. Hiện tượng này cũng đã xuất hiện khắp châu Âu trong hai tuần qua, bà Rousi nói.\\nNhững yếu tố trên có thể đã làm phát sinh vùng áp thấp tách biệt và cả vùng gió yếu ở châu Âu, từ đó khiến nhiệt độ cao dai dẳng ở đây, tiến sĩ Rousi nói.\\nMột số nguyên nhân khác\\nViệc châu Âu hứng chịu nhiều đợt sóng nhiệt hơn có thể còn có nguyên nhân khác, nhưng một vài nguyên nhân trong đó vẫn đang được giới khoa học tranh luận.\\nSự ấm lên ở Bắc Cực có thể góp phần vào hiện tượng nắng nóng gay gắt ở châu Âu, theo tiến sĩ Kornhuber. Khi Bắc Cực ấm lên với tốc độ nhanh hơn, chênh lệch nhiệt độ giữa Bắc Cực và đường xích đạo giảm dần. Điều này làm giảm lượng gió mùa hè, từ đó khiến các hệ thống thời tiết nán lại lâu hơn.\\nCác dấu hiệu khác cũng cho thấy sự biến đổi của một trong những dòng hải lưu lớn trên thế giới, Dòng đối lưu kinh tuyến Đại Tây Dương (AMOC), có thể tác động tới khí hậu châu Âu.\\nBằng mô phỏng máy tính, một nghiên cứu của tiến sĩ Rousi được phát công bố năm 2021 cho thấy việc AMOC yếu đi cùng lúc Trái Đất ấm lên sẽ tạo ra thay đổi trong hoàn lưu khí quyển, dẫn tới mùa hè khô hạn hơn ở châu Âu.\\nCũng như các khu vực khác trên thế giới, sóng nhiệt ở châu Âu còn có thể làm tăng khả năng xảy ra các làn sóng nhiệt mới tại cùng khu vực. Nguyên nhân là cái nóng cực đoan sẽ khiến đất đai khô cằn.\\nKhi đất còn ẩm, một phần năng lượng trong ánh Mặt Trời sẽ được dùng vào việc làm bốc hơi nước, từ đó tạo ra hiệu ứng làm mát nhẹ.\\nNhưng khi một làn sóng nhiệt lấy đi toàn bộ độ ẩm của đất, đất đai sẽ chẳng còn lại bao nhiêu hơi nước khi làn sóng tiếp theo xuất hiện. Khi ấy, hầu hết năng lượng từ ánh Mặt Trời sẽ nung nóng bề mặt đất, làm gia tăng cái nóng.'},\n",
       " {'title': \"Thế giới giữa 'tận thế nhiệt' \",\n",
       "  'anchor_text': 'Tận thế nhiệt là cụm từ mà tờ báo Anh The Guardian dùng để mô tả chuỗi thảm họa sóng nhiệt, cháy rừng, hạn hán... bủa vây nước Anh, châu Âu và nhiều vùng khác trên thế giới. ',\n",
       "  'raw_text': 'Châu Âu \"ôn đới\" không hề ôn hòa trong những ngày qua. Tại Bồ Đào Nha, ước tính đã có 1.000 người thiệt mạng do sóng nhiệt. Sóng nhiệt là tình trạng nhiệt độ duy trì trên 40 độ C, rất dễ dẫn đến sốc nhiệt, có nguy cơ tử vong nếu không được cấp cứu kịp thời.\\nTrong khi đó, lính cứu hỏa Tây Ban Nha, Bồ Đào Nha, Pháp, Hy Lạp, Ý... và nhiều quốc gia châu Âu khác đang vật lộn với các đám cháy rừng thảm khốc.\\nTại Anh, ngày 19-7 là một trong những ngày nóng nhất lịch sử, nóng tới nỗi nhà chức trách đã phải sợ đường ray xe lửa bị cháy do nắng nóng kết hợp với ma sát, không dám cho tàu chạy nhanh. Trong vài ngày qua, các đám cháy cũng bùng khắp nơi.\\nTại châu Á, Trung Quốc cũng đang chờ đón làn sóng nhiệt khốc liệt, dự kiến hoành hành ít nhất đến giữa tháng 8.\\nBên kia đại dương, Mỹ cũng rơi vào thảm cảnh. Nhiều vùng của Mỹ dự kiến sẽ đón hiện tượng thời tiết khốc liệt gọi là \"hơi thở của rồng\" trong những ngày tới.\\nĐất nước này được Cơ quan Quản lý khí quyển và đại dương Mỹ (NOAA) hứng chịu thảm họa do nhiệt nặng nề nhất tháng 6 với những đám cháy rừng liên miên, hạn hán nghiêm trọng.\\nVùng địa cực trước đây lạnh giá, nay cũng không thoát khỏi những đám cháy vì nóng và hạn hán.\\nNguyên nhân của \"tận thế nhiệt\" đơn giản mà dữ dội: Biến đổi khí hậu. Các thảm họa đã được dự báo trước và đã có những nỗ lực chống biến đổi khí hậu trong thời gian qua nhưng thường không đủ mạnh mẽ so với sức tàn phá của chính nhân loại.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]['single_documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Lời dặn dò tâm huyết của thầy cô trước khi học sinh bước vào kỳ thi THPT ',\n",
       " 'anchor_text': 'Trong 2 ngày 7 và 8/7/2022, hơn 1 triệu sĩ tử trên cả nước sẽ bắt đầu kỳ thi THPT Quốc gia năm 2022. Bước vào kỳ thi quan trọng này, tâm lý các thí sinh không tránh khỏi lo lắng. Giáo viên Hệ thống giáo dục Hocmai đưa ra những lời dặn dò hết sức tâm huyết và ý nghĩa dành cho các học trò. ',\n",
       " 'raw_text': 'TS Trịnh Thu Tuyết: Rà soát lại một lần nữa những đơn vị kiến thức cơ bản\\nChỉ còn vài ngày nữa, các em thực sự bước vào kì thi Tốt nghiệp THPT, với môn thi đầu tiên là môn Ngữ văn, áp lực với kì thi nói chung, với môn Ngữ văn nói riêng là không tránh khỏi. Tuy nhiên, đây cũng là thời điểm \"lúa sắp gặt, trái sắp chín\", công sức bao lâu sắp hiện trong thành quả của một kì thi thành công, và cô chỉ muốn nhắc các em vài điều cụ thể sau đây:\\n1. Thay vì lo lắng và áp lực, các em cần tích cực rà soát lại một lần nữa những đơn vị kiến thức cơ bản trong chương trình Ngữ văn lớp 12, ghi nhớ những giá trị nội dung và nghệ thuật chính của mỗi bài.\\n2. Tự kiểm tra lại hệ thống kỹ năng đáp ứng từng kiểu loại câu hỏi trong đề thi. Các em nên ôn tập theo các đơn vị kiến thức cơ bản trong mô hình đề thi mấy năm nay với ba phần: kiểu bài Đọc hiểu / viết đoạn văn nghị luận xã hội / viết bài văn nghị luận văn học.\\nPhần Đọc hiểu luôn gồm một ngữ liệu đọc hiểu và 4 câu hỏi đọc hiểu được sắp xếp theo các cấp độ nhận thức từ nhận biết, thông hiểu, vận dụng tới vận dụng cao. Các em cần nhận ra những tín hiệu của từng kiểu loại câu hỏi để có phương pháp trả lời phù hợp, tránh trả lời thừa hoặc thiếu. Ví dụ: câu hỏi nhận biết thường tập trung vào hai yêu cầu: hoặc yêu cầu xác định một đặc điểm của hình thức văn bản như thể thơ/ phong cách ngôn ngữ, phương thức biểu đạt…; hoặc yêu cầu tìm những chi tiết thuộc về nội dung văn bản phù hợp với nội dung định hướng trong câu lệnh – khi làm bài, học sinh cần đọc kỹ ngữ liệu, xác định đúng đặc điểm hình thức văn bản hoặc chi tiết nội dung văn bản, không phân tích diễn giải.\\nCâu hỏi thông hiểu thường yêu cầu giải thích cách hiểu nội dung một khái niệm/ nhận định/câu văn/ câu thơ…trong văn bản. Học sinh cần giải thích nghĩa đen/ nghĩa bóng, nghĩa ẩn dụ, biểu tượng ( nếu có) của khái niệm/ nhận định…\\nCâu hỏi vận dụng thường yêu cầu xác định và phân tích giá trị của biện pháp tu từ, tác dụng của việc sử dụng từ ngữ ... trong văn bản trong câu/ đoạn văn bản. Học sinh cần vận dụng kiến thức tiếng Việt, tu từ học, văn học, cuộc sống… để xác định đúng và phân tích giá trị biểu đạt và giá trị biểu cảm…\\nCâu hỏi vận dụng cao thường yêu cầu thể hiện cảm xúc, suy nghĩ, thái độ và nhất là quan điểm cá nhân trước một nhận định/ thông điệp/ vấn đề đặt ra trong văn bản đọc hiểu. Với dạng câu hỏi yêu cầu thể hiện cảm xúc, suy nghĩ về một hiện tượng, sự việc…, học sinh cần trả lời ngắn gọn, chân thành, trung thực những suy nghĩ, xúc cảm cá nhân, tránh khuôn mẫu, sáo rỗng, hô khẩu hiệu… Với dạng câu hỏi “Anh/chị có đồng tình…?/ Vì sao”, học sinh cần xác định đúng suy nghĩ, nhận thức của mình để luận bàn cho thấu đáo, chặt chẽ. Hoàn toàn có thể xuất hiện nhiều phương án: đồng tình/ không đồng tình/ đồng tình nhưng có giới hạn, điều kiện, ngoại lệ…. Phần quan trọng nhất là trả lời câu hỏi “Vì sao?” với lập luận chặt chẽ và trung thực, thuyết phục.\\nCâu viết đoạn văn nghị luận xã hội luôn có nội dung nghị luận quan hệ hữu cơ với nội dung chính của ngữ liệu đọc hiểu. Học sinh cần đặc biệt chú ý đảm bảo hai yêu cầu về nội dung và hình thức của đoạn văn: Về nội dung, chỉ nghị luận một khía cạnh, một bình diện của vấn đề (nguyên nhân/ ý nghĩa/ hậu quả/ giải pháp/ bài học…); về hình thức, cần viết đúng cấu trúc đoạn, viết đúng dung lượng theo yêu cầu trong câu lệnh của đề bài…\\nBài nghị luận văn học chiếm quỹ điểm cao nhất trong đề thi, đòi hỏi các em dành nhiều nhất thời gian và tâm sức. Cần xác định chính xác yêu cầu nghị luận thể hiện trong đề bài, đặc biệt trong câu lệnh, phác sơ lược hướng triển khai nội dung nghị luận để quá trình viết không lan man hoặc sơ sài. Nếu đoạn văn Nghị luận xã hội cần sự thể hiện cái tôi bản lĩnh, trung thực thì bài Nghị luận văn học rất cần khả năng cảm nhận tinh tế, sự phân tích sâu sắc và tình cảm chân thành.\\nThầy giáo Lưu Huy Thưởng (Giáo viên môn Toán) : Lưu ý 4 chiến thuật làm bài\\nChuẩn bị trước khi thi: Các em cần chuẩn bị đầy đủ các loại bút (bút bi, bút chì, gọt bút chì, tẩy) 3 - 5 cái; phiếu dự thi, máy tính, CMTND/CCCD, đồng hồ (phải có để canh chiến thuật làm bài), 1 chai nước (350 - 500ml) đã bóc nhãn.\\nTất cả cho hết vào 1 túi đựng tài liệu (Clear bag). Kinh nghiệm khi đi thi, lúc nộp bài đôi khi nhốn nháo, rất dễ bị \"hack\" mất đồ.\\nChiến thuật làm bài:\\n- DỄ TRƯỚC - KHÓ SAU: Mặc dù đề thi đã được sắp xếp từ dễ đến khó. Nhưng điều này chỉ mang tính chất tương đối. Có bạn giỏi Hình, có bạn lại sợ Hình.Cần làm chắc chắn, chính xác. 30 câu đầu\\n- NHÁP CẨN THẬN - KHOANH VÙNG RÕ RÀNG: Nháp xong 1 câu thì cách ra 1 chút rồi nháp câu tiếp.\\n- TÔ ĐÁP ÁN: Làm xong câu nào là tô luôn câu đó. Tránh tính trạng cuối giờ cuống lại 1 câu tô 2 đáp án. Hoặc khi làm ra A nhưng lại tô B do...nhìn nhầm\\n- CẢM XÚC LẦN ĐẦU RẤT QUAN TRỌNG: Có những lỗi sai ngớ ngẩn mà đôi khi kiểm tra lại cũng không phát hiện ra là mình sai. Bởi lẽ, lúc làm bài, ta đã ghi vào não \"Nó là đúng\" nên việc kiểm tra bước sau não thường hay bỏ qua. Ví dụ: 2+3 nhiều khi đi thi lại thành 6. Và khi kiểm tra lại thì não cũng bỏ qua bước này vì nghĩ nó quá dễ, sai làm sao được!! !\\nTối ưu hóa điểm số dựa trên mục tiêu\\nMỤC TIÊU 8-8,5 ĐIỂM: 45 phút đầu tiên làm hết 30 câu, 45 phút còn lại làm 20 câu còn lại (thực ra làm 10-13 câu còn lại) 7 câu cuối lụi.\\nMỤC TIÊU 9-9+ ĐIỂM: 45 phút đầu xong 40 câu, 45 phút còn lại dành cho 10 câu.\\nTS Nguyễn Thành Nam - Giảng viên Học viện Kỹ thuật Quân sự: Ưu tiên luyện tập chiến thuật làm bài thi\\nChỉ còn vài ngày nữa là đến kì thi tốt nghiệp THPT quốc gia, để có được sự chuẩn bị tốt nhất, các em cần lưu ý một số điểm sau đây:\\nVề sức khỏe, cần phải giữ sức khỏe ổn định bằng cách sinh hoạt điều độ. Không nên thức quá khuya, dậy quá sớm, và cần đảm bảo ngủ đủ giấc. Hạn chế những hành động có thể làm mất ổn định hoặc gây ra vấn đề cho sức khỏe, như vận động quá sức, ăn uống quá nhiều. Tránh ăn những loại thực phẩm lạ, khó tiêu hóa, hoặc dễ gây tiêu chảy, ngộ độc. Tóm lại giống như vận động viên trước khi thi đấu, các em cần phải giữ sức khỏe ở trạng thái tốt nhất có thể.\\nVề việc ôn thi, không nên tập trung vào học kiến thức mới nữa, mà nên ưu tiên luyện tập chiến thuật làm bài thi. Nên luyện tập trên một số đề thi chuẩn, và dựa vào mục tiêu điểm số của mình để kiểm soát thời gian cho hợp lí. Trong quá trình làm đề, cần lưu ý hoàn thiện kĩ thuật tính toán sao cho nhanh và chính xác. Tuyệt đối tránh việc phải tính đi tính lại nhiều lần một phép tính.\\nTrong quá trình làm bài thi, không nên quá suy nghĩ về những phần đã thi xong, mà nên tập trung vào phần đang làm. Nếu cảm thấy đề thi khó hơn mức bình thường thì cũng không cần phải lo lắng, vì điều này là hết sức bình thường. Trong trường hợp đề thi được nâng cao hơn về độ khó thì đó là cái khó chung, nên về cơ bản sẽ không làm thay đổi thứ hạng và kết quả tuyển sinh vào đại học của các thí sinh nên không cần phải bận tâm. Cần giữ trạng thái tâm lý ổn định và sự tập trung cao độ mới có thể đạt được kết quả tốt nhất.\\nCuối cùng, thầy chúc các em tham gia kỳ thi trong trạng thái tốt nhất, gặp nhiều may mắn trong quá trình thi, và đạt được kết quả cao nhất trong kỳ thi hết sức quan trọng này!\\nCô giáo Nguyễn Thị Thanh Hương (Cô Hương Fiona) - Giáo viên môn Tiếng Anh - Hệ thống Giáo dục HOCMAI: Làm thật chính xác và hiệu quả về mặt thời gian\\nVới bộ môn tiếng Anh, trong những năm thi gần đây, đề thi được giữ nguyên cấu trúc, dạng bài từ đó cũng tạo điều kiện thuận lợi cho việc ôn thi của các em. Các em học sinh hãy nắm chắc cấu trúc đề, ôn thật kĩ từng dạng câu hỏi theo chuyên đề giống với đề minh họa của Bộ giáo dục, và chú ý độ khó của từng dạng bài.\\nDạng bài đọc hiểu và đọc điền vốn là 2 dạng bài gây khó khăn nhất cho các em học sinh thi môn Tiếng Anh, lời khuyên của cô là hãy làm thật chính xác và hiệu quả về mặt thời gian cho những dạng bài còn lại trước, từ đó mình có thêm nhiều thời gian hơn cho 2 dạng bài này.\\nVới các bạn học sinh đặt mục tiêu 8 điểm, các em chỉ được phép “không chắc chắn” trong tầm 10 câu. Ở mức điểm này các bạn cần nắm thật vững các chuyên đề ngữ pháp, làm thành thục và tuyệt đối chính xác những câu hỏi này, tránh các lỗi sai đáng tiếc. Ở những dạng bài nâng cao về từ vựng, cố gắng hoàn thành tốt dạng bài đoán nghĩa ở bài Đồng nghĩa, trái nghĩa. Phần từ vựng khó như các câu hỏi về thành ngữ, cụm từ, ngữ động từ, từ vựng nâng cao… cố gắng chọn phương án tốt nhất theo đánh giá và năng lực của bản thân. Bài đọc điền, đọc hiểu hãy giải quyết chính xác những câu hỏi về ngữ pháp hay các câu hỏi về thông tin chi tiết, đại từ thay thế, từ vựng, đúng sai.\\nVới các bạn đạt mục tiêu điểm 9,10, các em chỉ được phép “không chắc chắn” không quá 5 câu hỏi. Để đạt được mức điểm này cần làm tuyệt đối chính xác các câu hỏi ở mức độ nhận biết, thông hiểu, vận dụng. Các câu hỏi vận dụng cao rơi vào câu về từ vựng nâng cao, câu hỏi suy luận và câu hỏi chủ đề của đọc hiểu.\\nCô Thiều Thị Dung (giáo viên môn Vật lý) : Tránh căng thẳng dẫn đến những sai sót không đáng có\\nĐể đạt được kết quả tốt nhất nhất với bài thi tốt nghiệp THPT môn Vật lí thì ngoài việc nắm vững hệ thống kiến thức và thành thạo các kĩ năng làm bài, các em cần chuẩn bị tâm lí vững vàng, tránh căng thẳng dẫn đến những sai sót không đáng có. Trong quá trình làm bài thi, các em cần lưu ý một số điểm sau:\\n- Đọc kỹ đề: Nhiều câu hỏi Vật lí chỉ cần thay đổi một vài từ trong đề bài, hoặc thay đổi thứ tự từ trong câu hỏi là ý nghĩa của các câu hỏi thay đổi hoàn toàn, nếu đọc đề bài một cách sơ sài chúng ta không thể nào phát hiện ra những yếu tố khác biệt đó sẽ dẫn đến những nhầm lẫn đáng tiếc. Khi làm xong các phép tính, các em cần lưu ý đơn vị ở câu trả lời của đề thi xem đáp số có phù hợp với thực tế không.\\n- Nháp thẳng vào đề thi: Để tránh nhầm lẫn trong quá trình tính toán, các em nên kí hiệu các đại lượng đề bài đã cho ngay trên đề thi, đồng thời đổi đơn vị và ghi công thức cần tính ngay trên đề.\\n- Phân bổ thời gian hợp lí: Số lượng câu hỏi thuộc cấp độ nhận biết, thông hiểu chiếm khoảng 28-30 câu nên các em cần ưu tiên xử lí nhanh, gọn, chính xác các câu hỏi này trong khoảng 15-20 phút. Sau đó dành khoảng 2 phút tô luôn đáp án toàn bộ các câu hỏi này vào phiếu trả lời. Thời gian còn lại các em quan sát nhanh các câu cuối, phân loại các câu hỏi có dạng quen thuộc và ưu tiên xử lí trước, câu lạ và khó xử lí sau. Hãy dành 5 phút cuối để kiểm tra lại đáp án của toàn bộ đề thi để chắc chắn không bỏ sót hoặc tô nhầm đáp án của câu hỏi nào.\\nChúc các em bước vào kỳ thi quan trọng với tâm thế thật tốt và gặt hái kết quả tốt nhất.\\nCô Nguyễn Thùy Linh (giáo viên môn Sinh học): Sau khi làm xong thì nên kiểm tra lại 2-3 lần\\n- Trước ngày thi nên đi ngủ sớm giúp tinh thần thoải mái và phát huy được tối đa khả năng trong lúc làm bài vào ngày thi hôm sau.\\n- Trong khi thi:\\n+ Chuẩn bị đầy đủ bút, máy tính trước khi bước vào phòng thi.\\n+ Khi được phát đề, đọc lướt qua một lượt (khoảng 1-2 phút) cả đề để biết độ dài và độ khó của đề để áng chừng tốc độ làm bài để đáp ứng được đề thi; nếu thấy đề thi bị mờ hoặc thiếu câu thì báo cho giám thị để xử lí.\\n+ Kiến thức 30 câu đầu thường ở mức Nhận biết - Thông hiểu nên các em cần làm nhanh, gạch chân được key word của câu hỏi, chú ý các câu hỏi chọn câu đúng/không đúng để tránh hiểu sai đề bài.\\n+ Ở 10 câu cuối, khi tính toán bị sai sót hoặc không nghĩ ra hướng của câu nào thì không nên hoảng loạn mà bỏ qua và làm câu tiếp theo, sau khi làm hết đề thì quay lại câu không làm được và tiếp tục giải, nếu không giải được thì thử đáp án lên nếu có thể.\\n+ Sau khi làm xong thì nên kiểm tra lại 2-3 lần (nếu có thời gian), ấn lại máy tính và kiểm tra xem đã tô đúng đáp án chưa.\\nLưu ý: Làm xong câu nào nên tô đáp án luôn câu đó, tránh làm xong mới tô có thể bị lệch đáp án và sai đáp án cả đề.\\n Cô Vũ Thị Thùy Dương (giáo viên môn Hóa học)\\n1. Chọn câu đơn giản (câu 1 – 28) làm trước, câu khó làm sau. (Vì mỗi câu hỏi trong đề thi môn Hóa học đều có giá trị 0,25 điểm/câu)\\n2. Chọn câu lí thuyết làm trước, câu tính toán làm sau. (Vì câu hỏi lí thuyết thường đơn giản hơn câu hỏi tính toán (trừ các câu hỏi lí thuyết thuộc nhóm câu từ 32-40)).\\n3. Nháp một cách khoa học (trên tờ nháp ghi rõ số thứ tự câu, nháp rõ ràng gọn gàng, … để dễ dàng xem lại khi cần).\\n4. Đọc kĩ đề, để ý các “bẫy” như: chọn phát biểu sai (tức đề hỏi tìm phát biểu sai chứ không phải tìm phát biểu đúng), quên cân bằng phương trình phản ứng, nhầm nguyên tử khối của các chất, nhầm danh pháp của các chất,…\\n5. Phân phối thời gian làm bài hợp lí: - Với các câu lí thuyết và tính toán đơn giản (khoảng 28-30 câu đầu), đọc đề, điền cẩn thận đáp án đúng vào phiếu câu trả lời (thời gian làm vùng câu hỏi này khoảng 15-20 phút). - Với các câu tính toán khó, viết số thứ tự câu ra nháp, tóm tắt lại đề bài để phân tích, làm bài, điền cẩn thận đáp án đúng vào phiếu câu trả lời (thời gian làm vùng câu hỏi này khoảng 20-25 phút). Với câu khó chưa làm được, đánh dấu hỏi chấm ở đầu số thứ tự câu trong đề, để đánh dấu câu đó chưa làm được, nếu còn thời gian làm bài có thể làm lại các câu này.\"\\n6. Dành 5 phút cuối giờ thi để kiểm tra lại thông tin về SBD, các đáp án đã khoanh (tránh khoanh nhầm đáp án), ....\\n Cô giáo Trần Vân Anh (Giáo viên môn Lịch sử): Làm chắc từ dễ đến khó\\nĐề có 4 cấp độ câu hỏi: Nhận biết - Thông hiểu - Vận dụng - Vận dụng cao. Nếu mong muốn 7 - 8 điểm, các em nên tập trung vào kiến thức trọng tâm và hiểu kiến thức đó trong bài.\\nĐể đạt được điểm cao hơn, cần liên hệ, kết nối giữa các phần kiến thức khác nhau trong bài và liên hệ kiến thức liên quan đến đời sống thực.\\nTuy nhiên cần, làm chắc từ dễ đến khó, từ đơn giản đến phức tạp, tận dụng thời gian hợp lý.\\nVí dụ: Với 40 câu trong 60 phút thì vòng 1 đọc tất cả các câu và khoanh các câu chắc đúng, tốc độ 1 phút x40 câu, câu nào không chắc chắn thì đánh dấu để sang câu tiếp theo. Vòng 2 chỉ làm các câu đánh dấu, phân tích kỹ hơn, nếu chưa làm được, dùng phương pháp loại trừ để loại bớt phương án nhiễu. Vòng 3, chỉ còn các câu khó, không chắc chắn, trường hợp chỉ còn 5 phút hết giờ thì chọn một trong số các phương án đang phân vân.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['single_documents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1= tokenizer(data[1]['single_documents'][0]['raw_text']+ data[1]['single_documents'][1]['raw_text']+ data[1]['single_documents'][2]['raw_text'], return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2992])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 177])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(data[16]['summary'], return_tensors='pt').input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset class\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "class Dataset4Summarization(Dataset):\n",
    "\tdef __init__(self, data, tokenizer, max_length=5096, chunk_length =1024, overlap=16):\n",
    "\t\tself.data = data\n",
    "\t\tself.tokenizer = tokenizer\n",
    "\t\tself.max_length = max_length\n",
    "\t\tself.chunk_length = chunk_length\n",
    "\t\tself.overlap = overlap\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.data)\n",
    "\n",
    "\tdef join_single_documents(self, single_documents):\n",
    "\t\ttext = \"\"\n",
    "\t\tfor documents in single_documents:\n",
    "\t\t\ttext += documents['raw_text'] + \" \"\n",
    "\t\treturn text\n",
    "\t\n",
    "\tdef chunking(self, text):\n",
    "\t\tchunks = []\n",
    "\t\tfor i in range(0, self.max_length, self.chunk_length-self.overlap):\n",
    "\t\t\tchunks.append(text[i:i+self.chunk_length])\n",
    "\t\treturn chunks\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tsample = self.data[idx]\n",
    "\t\ttext = self.join_single_documents(sample['single_documents'])\n",
    "\t\tinputs = self.tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=5096)\n",
    "\t\ttarget = self.tokenizer(sample['summary'], return_tensors='pt', padding='max_length', truncation=True, max_length=256)\n",
    "\t\tlist_chunk = self.chunking(inputs['input_ids'].squeeze())\n",
    "\t\tlist_attention_mask = self.chunking(inputs['attention_mask'].squeeze())\n",
    "\n",
    "\n",
    "\t\tdel text\n",
    "\t\tdel sample\n",
    "\t\treturn {\n",
    "\t\t\t'list_input_ids': list_chunk,\n",
    "\t\t\t'list_att_mask' : list_attention_mask,\n",
    "\t\t\t'target': target['input_ids'].squeeze()\n",
    "\t\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset4Summarization(data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1024])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for iter in train_loader:\n",
    "\tprint(iter['list_input_ids'][0].shape)\n",
    "\tprint(len(iter['list_input_ids']))\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_input = tokenizer(data[1]['single_documents'][0]['raw_text'], return_tensors='pt', padding='max_length', truncation=True, max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(36096, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(36096, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(36096, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ja = model.generate(input_ids=test1_input['input_ids'].to('cuda'), max_length=256, num_beams=4, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0, 3556, 2369,  128,  714, 1956,  411,  845,  823, 1119,    5,  718,\n",
       "         170,  204, 2534, 4214, 1956, 1620,  674,  195,  690,  996, 1220,    6,\n",
       "           1], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 48.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest1_input\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest1_input\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1739\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1736\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1739\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1106\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1091\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1092\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1093\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1103\u001b[0m         output_attentions,\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1106\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:686\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    684\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 686\u001b[0m self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m hidden_states, present_key_value_state \u001b[38;5;241m=\u001b[39m self_attention_outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    696\u001b[0m attention_outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:593\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    584\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    591\u001b[0m ):\n\u001b[1;32m    592\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 593\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    603\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (hidden_states,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:523\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    518\u001b[0m value_states \u001b[38;5;241m=\u001b[39m project(\n\u001b[1;32m    519\u001b[0m     hidden_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv, key_value_states, past_key_value[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    520\u001b[0m )\n\u001b[1;32m    522\u001b[0m \u001b[38;5;66;03m# compute scores\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m position_bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_relative_attention_bias:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "model(input_ids=test1_input['input_ids'].to('cuda'), attention_mask=test1_input['attention_mask'].to('cuda'), labels=test1_input['input_ids'].to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lần đầu tiên trong 6 năm, Anh ghi nhận nắng nóng trên 40 độ C, mức cao kỷ lục chưa từng có năm 2019.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ja[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eos_token': '</s>',\n",
       " 'unk_token': '<unk>',\n",
       " 'pad_token': '<pad>',\n",
       " 'additional_special_tokens': ['<extra_id_0>',\n",
       "  '<extra_id_1>',\n",
       "  '<extra_id_2>',\n",
       "  '<extra_id_3>',\n",
       "  '<extra_id_4>',\n",
       "  '<extra_id_5>',\n",
       "  '<extra_id_6>',\n",
       "  '<extra_id_7>',\n",
       "  '<extra_id_8>',\n",
       "  '<extra_id_9>',\n",
       "  '<extra_id_10>',\n",
       "  '<extra_id_11>',\n",
       "  '<extra_id_12>',\n",
       "  '<extra_id_13>',\n",
       "  '<extra_id_14>',\n",
       "  '<extra_id_15>',\n",
       "  '<extra_id_16>',\n",
       "  '<extra_id_17>',\n",
       "  '<extra_id_18>',\n",
       "  '<extra_id_19>',\n",
       "  '<extra_id_20>',\n",
       "  '<extra_id_21>',\n",
       "  '<extra_id_22>',\n",
       "  '<extra_id_23>',\n",
       "  '<extra_id_24>',\n",
       "  '<extra_id_25>',\n",
       "  '<extra_id_26>',\n",
       "  '<extra_id_27>',\n",
       "  '<extra_id_28>',\n",
       "  '<extra_id_29>',\n",
       "  '<extra_id_30>',\n",
       "  '<extra_id_31>',\n",
       "  '<extra_id_32>',\n",
       "  '<extra_id_33>',\n",
       "  '<extra_id_34>',\n",
       "  '<extra_id_35>',\n",
       "  '<extra_id_36>',\n",
       "  '<extra_id_37>',\n",
       "  '<extra_id_38>',\n",
       "  '<extra_id_39>',\n",
       "  '<extra_id_40>',\n",
       "  '<extra_id_41>',\n",
       "  '<extra_id_42>',\n",
       "  '<extra_id_43>',\n",
       "  '<extra_id_44>',\n",
       "  '<extra_id_45>',\n",
       "  '<extra_id_46>',\n",
       "  '<extra_id_47>',\n",
       "  '<extra_id_48>',\n",
       "  '<extra_id_49>',\n",
       "  '<extra_id_50>',\n",
       "  '<extra_id_51>',\n",
       "  '<extra_id_52>',\n",
       "  '<extra_id_53>',\n",
       "  '<extra_id_54>',\n",
       "  '<extra_id_55>',\n",
       "  '<extra_id_56>',\n",
       "  '<extra_id_57>',\n",
       "  '<extra_id_58>',\n",
       "  '<extra_id_59>',\n",
       "  '<extra_id_60>',\n",
       "  '<extra_id_61>',\n",
       "  '<extra_id_62>',\n",
       "  '<extra_id_63>',\n",
       "  '<extra_id_64>',\n",
       "  '<extra_id_65>',\n",
       "  '<extra_id_66>',\n",
       "  '<extra_id_67>',\n",
       "  '<extra_id_68>',\n",
       "  '<extra_id_69>',\n",
       "  '<extra_id_70>',\n",
       "  '<extra_id_71>',\n",
       "  '<extra_id_72>',\n",
       "  '<extra_id_73>',\n",
       "  '<extra_id_74>',\n",
       "  '<extra_id_75>',\n",
       "  '<extra_id_76>',\n",
       "  '<extra_id_77>',\n",
       "  '<extra_id_78>',\n",
       "  '<extra_id_79>',\n",
       "  '<extra_id_80>',\n",
       "  '<extra_id_81>',\n",
       "  '<extra_id_82>',\n",
       "  '<extra_id_83>',\n",
       "  '<extra_id_84>',\n",
       "  '<extra_id_85>',\n",
       "  '<extra_id_86>',\n",
       "  '<extra_id_87>',\n",
       "  '<extra_id_88>',\n",
       "  '<extra_id_89>',\n",
       "  '<extra_id_90>',\n",
       "  '<extra_id_91>',\n",
       "  '<extra_id_92>',\n",
       "  '<extra_id_93>',\n",
       "  '<extra_id_94>',\n",
       "  '<extra_id_95>']}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 4])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = torch.randn(2, 3, 4)\n",
    "xy = torch.randn(2, 3, 4)\n",
    "a = [xx, xy]\n",
    "torch.cat(a, dim=1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, fused=True )\n",
    "critertion = torch.nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, model1, train_loader, optimizer, scheduler, criterion, epochs, device):\n",
    "\tmodel.train()\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tfor iter in train_loader:\n",
    "\t\t\tsummaries = []\n",
    "\t\t\tmodel.zero_grad(set_to_none=True)\n",
    "\t\t\tinputs = iter['list_input_ids']\n",
    "\t\t\tatt_mask = iter['list_att_mask']\n",
    "\t\t\ttarget = iter['target'].to(device)\n",
    "\t\t\tfor i in range(len(inputs)):\n",
    "\t\t\t\tinputs[i] = inputs[i].to(device)\n",
    "\t\t\t\t# att_mask[i] = att_mask[i].to(device)\n",
    "\t\t\t\tsummary = model.generate(inputs[i], max_length=64, num_beams=4, early_stopping=True)\n",
    "\t\t\t\tsummaries.append(summary)\n",
    "\t\t\tsummaries = torch.cat(summaries, dim=1).to(device)\n",
    "\t\t\t# summaries = model.generate(summaries, max_length=256, num_beams=4)\n",
    "\t\t\t# del inputs\n",
    "\t\t\tif summaries.shape[1] > 256:\n",
    "\t\t\t\tsummaries = summaries[:, :256]\n",
    "\t\t\t\tatt_mask = torch.ones((summaries.shape[0], 256)).to(device)\n",
    "\t\t\telse:\n",
    "\t\t\t\tatt_mask = torch.ones((summaries.shape[0], summaries.shape[1])).to(device)\n",
    "\t\t\t\tsummaries = torch.nn.functional.pad(summaries, (0, 256-summaries.shape[1]), value=0)\n",
    "\t\t\t\tatt_mask = torch.nn.functional.pad(att_mask, (0, 256-att_mask.shape[1]), value=0)\n",
    "\t\t\t\n",
    "\t\t\tsummaries = model1(summaries,attention_mask=att_mask, labels=target)\n",
    "\t\t\tloss = summaries.loss\n",
    "\n",
    "\t\t\ttorch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\t\n",
    "\t\t\tprint(loss.item())\n",
    "\t\tscheduler.step()\n",
    "\t\tprint(f'Epoch {epoch} done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256])\n",
      "torch.Size([2, 56])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"host_softmax\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcritertion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 21\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(model, train_loader, optimizer, scheduler, criterion, epochs, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(summaries\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     20\u001b[0m padded_summaries \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(summaries, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m256\u001b[39m\u001b[38;5;241m-\u001b[39msummaries\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43msummaries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     24\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/loss.py:1185\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"host_softmax\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "train_fn(model, train_loader, optimizer, scheduler, critertion, 1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 56])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = torch.randn(2,39)\n",
    "padded = torch.nn.functional.pad(xx, (0,  56-39), value=0)\n",
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 1], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(tokenizer.special_tokens_map['pad_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practic1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
